{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 Project (Titanic)\n",
    "Jason Ballard\n",
    "4 April 2025\n",
    "\n",
    "Import the external Python libraries used (e.g., pandas, numpy, matplotlib, seaborn, sklearn and more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports get moved to the top - import each only once\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "features = list(df.columns)\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic.info()\n",
    "# print(titanic.head(10))\n",
    "# titanic.isnull().sum()\n",
    "# print(titanic.describe())\n",
    "# print(titanic.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes = ['age', 'fare', 'pclass']\n",
    "# scatter_matrix(titanic[attributes], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(titanic['age'], titanic['fare'], c=titanic['sex'].apply(lambda x: 0 if x == 'male' else 1))\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Fare')\n",
    "# plt.title('Age vs Fare by Gender')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a histogram of age:\n",
    "\n",
    "# sns.histplot(titanic['age'], kde=True)\n",
    "# plt.title('Age Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a count plot for class and survival:\n",
    "\n",
    "# sns.countplot(x='class', hue='survived', data=titanic)\n",
    "# plt.title('Class Distribution by Survival')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].fillna(df['age'].median())\n",
    "\n",
    "titanic = df.dropna(subset=['fare'])\n",
    "\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.1:\n",
    "\n",
    "1. What patterns or anomalies do you notice? Young to middle age passengers, majority found in third class\n",
    "2. Do any features stand out as potential predictors? the deck location or fare price\n",
    "3. Are there any visible class imbalances? There are huge class imbalances. Majority of the passengers where younger families traveling to the USA -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handle Missing Values and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mode found for 'embark_town'\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values in 'age' with the median age\n",
    "df['age'].fillna(df['age'].median())\n",
    "\n",
    "# Impute missing values in 'embark_town' with the mode (most common value)\n",
    "mode_val = df['embark_town'].mode()\n",
    "if not mode_val.empty:\n",
    "    df['embark_town'].fillna(mode_val[0])\n",
    "else:\n",
    "    print(\"No mode found for 'embark_town'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature: Family size\n",
    "# This is the coveresion of catagorical dat inot numerical data\n",
    "\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1 \n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "df['embark_town'] = df['embark_town'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "df['alone'] = df['alone'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.3\n",
    "\n",
    "1. Why might family size be a useful feature for predicting survival? famil;y size is a good prediction of survivalbility for the female and younger children of the families\n",
    "2. Why convert categorical data to numeric?  the conversion allows computations to be run on the data. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Feature Selection and Justification\n",
    "\n",
    "- Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "- Use 'Survived' as the target\n",
    "\n",
    "First:\n",
    "- input features: alone\n",
    "- target: survived\n",
    "\n",
    "Second:\n",
    "- input features - embark_town\n",
    "- target: survived\n",
    "\n",
    "Third:\n",
    "- input features -  age and family_size (embark_town)\n",
    "- target: survived\n",
    "- Justify your selection with reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Choose features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Assuming your Titanic data has already been encoded and stored in df_encoded\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m X = \u001b[43mdf_encoded\u001b[49m.drop(\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m y = df_encoded[\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Train a Decision Tree to get feature importances\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df_encoded.drop(\"class\", axis=1)\n",
    "y = df_encoded[\"class\"]\n",
    "\n",
    "# Train a Decision Tree to get feature importances\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X, y)\n",
    "\n",
    "# Get and sort feature importances\n",
    "importances = pd.Series(dt.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Plot Top 10 Important Features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances.values[:10], y=importances.index[:10])\n",
    "plt.title(\"Top 10 Important Features (Decision Tree)\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/Top_10_features.png', dpi=300)  # Save the plot\n",
    "plt.show()  # Optional: show in notebook\n",
    "plt.close()\n",
    "\n",
    "# Scaling – Required for distance-based models like SVM, MLP\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Wrap into DataFrame for easy use/inspection\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Confirm scaled data\n",
    "print(\"\\nScaled Feature Sample:\")\n",
    "print(X_scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'family_size' (sum of siblings/spouses and parents/children aboard)\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1  # +1 to include the passenger themselves\n",
    "\n",
    "# Select relevant features for classification\n",
    "features = ['alone', 'age', 'embark_town', 'sex', 'family_size']\n",
    "target = 'survived'\n",
    "\n",
    "# Extract relevant columns\n",
    "titanic_classification = df[features + [target]]\n",
    "\n",
    "# Encode categorical variable 'sex' (convert 'male'/'female' to 0/1)\n",
    "titanic_classification['sex'] = titanic_classification['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Drop rows with missing values\n",
    "titanic_classification = titanic_classification.dropna()\n",
    "\n",
    "# Display the processed dataset\n",
    "print(titanic_classification.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define X (features) and y (target)\n",
    "- Assign input features to X a pandas DataFrame with 1 or more input features\n",
    "- Assign target variable to y (as applicable) - a pandas Series with a single target feature\n",
    "- Again - use comments to run a single case at a time\n",
    "\n",
    "- The follow starts with only the statements needed for case 1. \n",
    "- Double brackets [[ ]]  makes a 2D DataFrame\n",
    "- Single brackets [ ]  make a 1D Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1 Assign input features to X = (alone)\n",
    "X = df['alone']\n",
    "# Assign target variable to y (as applicable)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 Assign input features to X = embarked\n",
    "X = df['embark_town']\n",
    "# Assign target variable to y (as applicable)   \n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Case 3 Assign input features to X = \n",
    "X = df[['age', 'embark_town', 'family_size']]\n",
    "# Assign target variable to y (as applicable)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "\n",
    "1. Why are these features selected? the features selected provide the most tell of survivability\n",
    "2. Are there any features that are likely to be highly predictive of survival? Yes age and class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Train a Classification Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Basic Train/Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print('Train size:', len(X_train))\n",
    "print('Test size:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Stratified Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    train_set = X.iloc[train_indices]\n",
    "    test_set = X.iloc[test_indices]\n",
    "\n",
    "print('Train size:', len(train_set))\n",
    "print('Test size:', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Compare Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"Original Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Train Set Class Distribution:\\n\", train_set['pclass'].value_counts(normalize=True))\n",
    "print(\"Test Set Class Distribution:\\n\", test_set['pclass'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "\n",
    "1. Why might stratification improve model performance? this ensures that the data is equallly representivate across the whole data set. \n",
    "2. How close are the training and test distributions to the original dataset?\n",
    "3. Which split method produced better class balance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Compare Alternative Models (SVC, NN)\n",
    "In a Support Vector Machine, the kernel function defines how the algorithm transforms data to find a hyperplane that separates the classes. If the data is not linearly separable, changing the kernel can help the model find a better decision boundary.\n",
    "\n",
    "SVC Kernel: Common Types\n",
    "\n",
    "* RBF (Radial Basis Function) – Most commonly used; handles non-linear data well (default)\n",
    "* Linear – Best for linearly separable data (straight line separation)\n",
    "* Polynomial – Useful when the data follows a curved pattern\n",
    "* Sigmoid – Similar to a neural network activation function; less common\n",
    "\n",
    "_**Commenting the options in and out in the code can be helpful. The analyst decides which to use based on their understanding of the results.**_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF Kernel (default) - same as calling SVC()\n",
    "svc_model = SVC(kernel='rbf')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Linear Kernel\n",
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Polynomial Kernel (e.g., with degree=3)\n",
    "svc_model = SVC(kernel='poly', degree=3)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Sigmoid Kernel\n",
    "svc_model = SVC(kernel='sigmoid')\n",
    "svc_model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
