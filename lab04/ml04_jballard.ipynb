{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 Project (Titanic)\n",
    "Jason Ballard\n",
    "4 April 2025\n",
    "\n",
    "Import the external Python libraries used (e.g., pandas, numpy, matplotlib, seaborn, sklearn and more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 1.6.1\n",
      "Location: c:\\Users\\balla\\Projects\\applied-ml-jballard\\.venv\\Lib\\site-packages\\sklearn\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "# all imports get moved to the top - import each only once\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "print(\"Version:\", sklearn.__version__)\n",
    "print(\"Location:\", sklearn.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder if it doesn't exist\n",
    "output_dir = \"plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n",
      "['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "features = list(df.columns)\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "\n",
    "df['survived'] = df['survived'].fillna(df['survived'].median())\n",
    "\n",
    "titanic = df.dropna(subset=['fare'])\n",
    "\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.1:\n",
    "\n",
    "1. What patterns or anomalies do you notice? Young to middle age passengers, majority found in third class\n",
    "2. Do any features stand out as potential predictors? the deck location or fare price\n",
    "3. Are there any visible class imbalances? There are huge class imbalances. Majority of the passengers where younger families traveling to the USA -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handle Missing Values and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in 'age' with the median age\n",
    "df['age'].fillna(df['age'].median())\n",
    "\n",
    "# Fill missing values in 'survived' with the median age\n",
    "df['survived'].fillna(df['survived'].median())\n",
    "\n",
    "# Impute missing values in 'fare' with the mode (most common value)\n",
    "mode_val = df['fare'].mode()\n",
    "if not mode_val.empty:\n",
    "    df['fare'].fillna(mode_val[0])\n",
    "else:\n",
    "    print(\"No mode found for 'fare'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature 'family_size' (sum of siblings/spouses and parents/children aboard)\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1  # +1 to include the passenger themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.3\n",
    "\n",
    "1. Why might family size be a useful feature for predicting survival? famil;y size is a good prediction of survivalbility for the female and younger children of the families\n",
    "2. Why convert categorical data to numeric?  the conversion allows computations to be run on the data. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Feature Selection and Justification\n",
    "\n",
    "- Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "- Use 'Survived' as the target\n",
    "\n",
    "First:\n",
    "- input features: age\n",
    "- target: fare\n",
    "\n",
    "Second:\n",
    "- input features - family size\n",
    "- target: fare\n",
    "\n",
    "Third:\n",
    "- input features -  age, family_size\n",
    "- target: fare\n",
    "\n",
    "Fourth: \n",
    "- input feature - survived \n",
    "- target - fare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Choose features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features for classification\n",
    "features = ['age', 'family_size', 'pclass']\n",
    "target = 'fare'\n",
    "\n",
    "# Extract relevant columns\n",
    "titanic_classification = df[features + [target]]\n",
    "\n",
    "# Drop rows with missing values\n",
    "titanic_classification = titanic_classification.dropna()\n",
    "\n",
    "# Display the processed dataset\n",
    "print(titanic_classification.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define X (features) and y (target)\n",
    "- Assign input features to X a pandas DataFrame with 1 or more input features\n",
    "- Assign target variable to y (as applicable) - a pandas Series with a single target feature\n",
    "- Again - use comments to run a single case at a time\n",
    "\n",
    "- The follow starts with only the statements needed for case 1. \n",
    "- Double brackets [[ ]]  makes a 2D DataFrame\n",
    "- Single brackets [ ]  make a 1D Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1 Assign input features to X = (alone)\n",
    "X1 = df[['age']]\n",
    "# Assign target variable to y (as applicable)\n",
    "y1 = df['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 Assign input features to X = embarked\n",
    "X2 = df[['family_size']]\n",
    "# Assign target variable to y (as applicable)   \n",
    "y2 = df['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Case 3 Assign input features to X = \n",
    "X3 = df[['age', 'family_size']]\n",
    "# Assign target variable to y (as applicable)\n",
    "y3 = df['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Case 4 Assign input features to X = \n",
    "X4 = df[['age', 'family_size', 'pclass']]\n",
    "# Assign target variable to y (as applicable)\n",
    "y4 = df['fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "\n",
    "**Why might these features affect a passenger’s fare:** Features like pclass, age, and family_size make sense because they reflect how much comfort or space a passenger might need. People in first class paid more, younger passengers or families may have gotten discounts, and large families might’ve booked cheaper group tickets.\n",
    "\n",
    "**List all available features:** survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone'\n",
    "\n",
    "**Which other features could improve predictions and why:** sex, embarked, and deck could be helpful. For example, deck could show how fancy a cabin was, and that might link to fare. sex might also reflect who got access to better accommodations or family packages.\n",
    "\n",
    "**How many variables are in your Case 4:** Three — pclass, age, and family_size.\n",
    "\n",
    "**Which variable(s) did you choose for Case 4 and why do you feel those could make good inputs:** I chose pclass, age, and family_size because they cover a mix of socioeconomic status (class), personal characteristics (age), and travel group size. Together, they help the model better understand fare differences between passengers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Train a Classification Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Basic Train/Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=123)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=123)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=123)\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model1 = LinearRegression().fit(X1_train, y1_train)\n",
    "lr_model2 = LinearRegression().fit(X2_train, y2_train)\n",
    "lr_model3 = LinearRegression().fit(X3_train, y3_train)\n",
    "lr_model4 = LinearRegression().fit(X4_train, y4_train)\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_pred_train1 = lr_model1.predict(X1_train)\n",
    "y_pred_test1 = lr_model1.predict(X1_test)\n",
    "\n",
    "y_pred_train2 = lr_model2.predict(X2_train)\n",
    "y_pred_test2 = lr_model2.predict(X2_test)\n",
    "\n",
    "y_pred_train3 = lr_model3.predict(X3_train)\n",
    "y_pred_test3 = lr_model3.predict(X3_test)\n",
    "\n",
    "y_pred_train4 = lr_model4.predict(X4_train)\n",
    "y_pred_test4 = lr_model4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Compare Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Case 1: Training R²:\", r2_score(y1_train, y_pred_train1))\n",
    "print(\"Case 1: Test R²:\", r2_score(y1_test, y_pred_test1))\n",
    "print(\"Case 1: Test RMSE:\", mean_squared_error(y1_test, y_pred_test1))\n",
    "print(\"Case 1: Test MAE:\", mean_absolute_error(y1_test, y_pred_test1))\n",
    "\n",
    "print(\"Case 2: Training R²:\", r2_score(y2_train, y_pred_train2))\n",
    "print(\"Case 2: Test R²:\", r2_score(y2_test, y_pred_test2))\n",
    "print(\"Case 2: Test RMSE:\", mean_squared_error(y2_test, y_pred_test2))\n",
    "print(\"Case 2: Test MAE:\", mean_absolute_error(y2_test, y_pred_test2))\n",
    "\n",
    "print(\"Case 3: Training R²:\", r2_score(y3_train, y_pred_train3))\n",
    "print(\"Case 3: Test R²:\", r2_score(y3_test, y_pred_test3))\n",
    "print(\"Case 3: Test RMSE:\", mean_squared_error(y3_test, y_pred_test3))\n",
    "print(\"Case 3: Test MAE:\", mean_absolute_error(y3_test, y_pred_test3))\n",
    "\n",
    "print(\"Case 4: Training R²:\", r2_score(y4_train, y_pred_train4))\n",
    "print(\"Case 4: Test R²:\", r2_score(y4_test, y_pred_test4))\n",
    "print(\"Case 4: Test RMSE:\", mean_squared_error(y4_test, y_pred_test4))\n",
    "print(\"Case 4: Test MAE:\", mean_absolute_error(y1_test, y_pred_test4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "\n",
    "**Compare the train vs test results for each.**\n",
    "\n",
    "1. **Did Case 1 overfit or underfit?**  **Underfit**  *Explain:* The model didn’t do well on either the training or test data. Age by itself doesn’t explain fare — it’s basically just guessing near the average for everyone.\n",
    "\n",
    "2. **Did Case 2 overfit or underfit?**  **Underfit**  *Explain:* It performed slightly better than Case 1, but still didn’t capture much of the variation. Family size might only affect fare indirectly — like through group discounts or shared tickets.\n",
    "\n",
    "3. **Did Case 3 overfit or underfit?**  **Underfit**  *Explain:* Adding both age and family size helped a bit more. The model started to pick up a weak pattern, but still wasn’t strong enough to make reliable predictions.\n",
    "\n",
    "4. **Did Case 4 overfit or underfit?**  **Mild underfit, but much better**  *Explain:* This case was a big step up. The model performed noticeably better on both training and test sets. While it’s still not perfect, it captured a lot more of the variation in fare compared to the other models.\n",
    "\n",
    "**Adding Age**\n",
    "\n",
    "1. **Did adding age improve the model?**  **Yes** — a little. When age was combined with family size in Case 3, it performed slightly better than either one alone.\n",
    "\n",
    "2. **Possible explanation:**  Age may have a minor effect on fare — for example, younger kids could have received reduced rates, or families with children might have booked cheaper group tickets. Still, age didn’t seem to be a major driver of fare in the data.\n",
    "\n",
    "**Worst**\n",
    "\n",
    "1. **Which case performed the worst?**  **Case 1** — the model using only age.\n",
    "\n",
    "2. **How do you know?**  It had the lowest R² scores and the highest RMSE. That tells us it couldn’t detect any real pattern — it was just slightly better than predicting the mean fare.\n",
    "\n",
    "3. **Would more training data help?**  Probably not. Age alone doesn’t provide enough information to predict fare, so even with more data, the model would still struggle.\n",
    "\n",
    "**Best**\n",
    "\n",
    "1. **Which case performed the best?**  **Case 4** — the model using a combination of features.\n",
    "\n",
    "2. **How do you know?**  It had the highest R² on both train and test sets, and the lowest RMSE and MAE. That means it captured more of the actual relationship between the input features and fare.\n",
    "\n",
    "3. **Would more training data help?**  Maybe. The model is doing a lot better, so more data could help it learn the patterns even more clearly — especially if the added data includes more variation in class, age, or group sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Compare Alternative Models\n",
    "In this section, we will take the best-performing case and explore other regression models.\n",
    "\n",
    "Choose Best Case to Continue\n",
    "Choose the best case model from the four cases. Use that model to continue to explore additional continuous prediction models. The following assumes that Case 1 was the best predictor  - this may not be the case. Adjust the code to use your best case model instead. \n",
    "\n",
    "Choosing Options\n",
    "When working with regression models, especially those with multiple input features, we may run into overfitting — where a model fits the training data too closely and performs poorly on new data. To prevent this, we can apply regularization.\n",
    "\n",
    "Regularization adds a penalty to the model’s loss function, discouraging it from using very large weights (coefficients). This makes the model simpler and more likely to generalize well to new data.\n",
    "\n",
    "In general: \n",
    "\n",
    "If the basic linear regression is overfitting, try Ridge.\n",
    "\n",
    "If you want the model to automatically select the most important features, try Lasso.\n",
    "\n",
    "If you want a balanced approach, try Elastic Net.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Ridge Regression (L2 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression CASE 1\n",
    "# Create a Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X1_train, y1_train)\n",
    "\n",
    "#predict on the test set\n",
    "y_pred_ridge = ridge_model.predict(X1_test)\n",
    "\n",
    "# Evaluate\n",
    "ridge_r2 = r2_score(y1_test, y_pred_ridge)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y1_test, y_pred_ridge))\n",
    "ridge_mae = mean_absolute_error(y1_test, y_pred_ridge)\n",
    "\n",
    "# Print results\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(f\"  R²:   {ridge_r2:.4f}\")\n",
    "print(f\"  RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"  MAE:  {ridge_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression CASE 4\n",
    "# Create a Ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X4_train, y4_train)\n",
    "\n",
    "#predict on the test set\n",
    "y_pred_ridge = ridge_model.predict(X4_test)\n",
    "\n",
    "# Evaluate\n",
    "ridge_r2 = r2_score(y4_test, y_pred_ridge)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y4_test, y_pred_ridge))\n",
    "ridge_mae = mean_absolute_error(y4_test, y_pred_ridge)\n",
    "\n",
    "# Print results\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(f\"  R²:   {ridge_r2:.4f}\")\n",
    "print(f\"  RMSE: {ridge_rmse:.2f}\")\n",
    "print(f\"  MAE:  {ridge_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Elastic Net (L1 + L2 combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet Regression Case 1\n",
    "# Create an ElasticNet regression model\n",
    "elastic_model = ElasticNet(alpha=0.3, l1_ratio=0.5)\n",
    "elastic_model.fit(X1_train, y1_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_elastic = elastic_model.predict(X1_test)\n",
    "\n",
    "# Evaluate\n",
    "elastic_r2 = r2_score(y1_test, y_pred_elastic)\n",
    "elastic_rmse = np.sqrt(mean_squared_error(y1_test, y_pred_elastic))\n",
    "elastic_mae = mean_absolute_error(y1_test, y_pred_elastic)\n",
    "\n",
    "# Print results\n",
    "print(\"ElasticNet Regression Results:\")\n",
    "print(f\"  R²:   {elastic_r2:.4f}\")\n",
    "print(f\"  RMSE: {elastic_rmse:.2f}\")\n",
    "print(f\"  MAE:  {elastic_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet Regression Case 4\n",
    "# Create an ElasticNet regression model\n",
    "elastic_model = ElasticNet(alpha=0.3, l1_ratio=0.5)\n",
    "elastic_model.fit(X4_train, y4_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_elastic = elastic_model.predict(X4_test)\n",
    "\n",
    "# Evaluate\n",
    "elastic_r2 = r2_score(y4_test, y_pred_elastic)\n",
    "elastic_rmse = np.sqrt(mean_squared_error(y4_test, y_pred_elastic))\n",
    "elastic_mae = mean_absolute_error(y4_test, y_pred_elastic)\n",
    "\n",
    "# Print results\n",
    "print(\"ElasticNet Regression Results:\")\n",
    "print(f\"  R²:   {elastic_r2:.4f}\")\n",
    "print(f\"  RMSE: {elastic_rmse:.2f}\")\n",
    "print(f\"  MAE:  {elastic_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the poly inputs CASE 1\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly.fit_transform(X1_train)\n",
    "X_test_poly = poly.transform(X1_test)\n",
    "\n",
    "\n",
    "print(\"Poly train shape:\", X_train_poly.shape)\n",
    "print(\"Poly test shape:\", X_test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the poly inputs in the LR model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y1_train)\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Evaluate\n",
    "poly_r2 = r2_score(y1_test, y_pred_poly)\n",
    "poly_rmse = np.sqrt(mean_squared_error(y1_test, y_pred_poly))\n",
    "poly_mae = mean_absolute_error(y1_test, y_pred_poly)\n",
    "\n",
    "# Print results\n",
    "print(\"Polynomial Regression Results:\")\n",
    "print(f\"  R²:   {poly_r2:.4f}\")\n",
    "print(f\"  RMSE: {poly_rmse:.2f}\") \n",
    "print(f\"  MAE:  {poly_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualize Polynomial Cubic Fit (for 3 input feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting predictions vs one feature (e.g., age)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X4_test['age'], y4_test, color='blue', label='Actual')\n",
    "plt.scatter(X4_test['age'], y_pred_poly, color='red', label='Predicted (Poly)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.legend()\n",
    "plt.title(\"Polynomial Regression: Age vs Fare (Predicted vs Actual)\")\n",
    "plt.savefig(\"plots/age_vs_fare.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting predictions vs family size\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X4_test['family_size'], y4_test, color='blue', label='Actual')\n",
    "plt.scatter(X4_test['family_size'], y_pred_poly, color='red', label='Predicted (Poly)')\n",
    "plt.xlabel('Family Size')\n",
    "plt.ylabel('Fare')\n",
    "plt.legend()\n",
    "plt.title(\"Polynomial Regression: Family Size vs Fare (Predicted vs Actual)\")\n",
    "plt.savefig(\"plots/family_size_vs_fare.png\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting predictions vs pclass\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X4_test['pclass'], y4_test, color='blue', label='Actual')\n",
    "plt.scatter(X4_test['pclass'], y_pred_poly, color='red', label='Predicted (Poly)')\n",
    "plt.xlabel('Pclass')\n",
    "plt.ylabel('Fare')\n",
    "plt.legend()\n",
    "plt.title(\"Polynomial Regression: Pclass vs Fare (Predicted vs Actual)\")\n",
    "plt.savefig(\"plots/pclass_vs_fare.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Reflections \n",
    "\n",
    "1. **What patterns does the cubic model seem to capture:** It catches the general idea that people in higher classes paid more and that fare might change a bit with age or family size. It’s not perfect, but it picks up some of the trends.\n",
    "\n",
    "2. **Where does it perform well or poorly:** It does pretty well in the middle — like average ages, family sizes, and class 1 passengers. It struggles with really high fares or weird combos, like big families or older passengers in lower classes.\n",
    "\n",
    "3. **Did the polynomial fit outperform linear regression:** Yeah, a little. It improved things, but not by a huge amount. It just helped the model be a bit more flexible.\n",
    "\n",
    "4. **Where (on the graph or among which kinds of data points) does it fit best:** Mostly where the data is pretty normal — like younger passengers, smaller families, and people in first class. It doesn’t do so well with outliers or rare cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report Case `1` results\n",
    "\n",
    "def report(name, y_true, y_pred):\n",
    "    print(f\"{name} R²: {r2_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"{name} RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.2f}\")\n",
    "    print(f\"{name} MAE: {mean_absolute_error(y_true, y_pred):.2f}\\n\")\n",
    "\n",
    "report(\"Linear\", y1_test, y_pred_test1)\n",
    "report(\"Ridge\", y1_test, y_pred_ridge)\n",
    "report(\"ElasticNet\", y1_test, y_pred_elastic)\n",
    "report(\"Polynomial\", y1_test, y_pred_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report Case `4` results\n",
    "\n",
    "def report(name, y_true, y_pred):\n",
    "    print(f\"{name} R²: {r2_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"{name} RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.2f}\")\n",
    "    print(f\"{name} MAE: {mean_absolute_error(y_true, y_pred):.2f}\\n\")\n",
    "\n",
    "report(\"Linear\", y4_test, y_pred_test4)\n",
    "report(\"Ridge\", y4_test, y_pred_ridge)\n",
    "report(\"ElasticNet\", y4_test, y_pred_elastic)\n",
    "report(\"Polynomial\", y4_test, y_pred_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use just one feature for simplicity (e.g., 'age')\n",
    "X_age_train = X1_train[['age']]\n",
    "X_age_test = X1_test[['age']]\n",
    "\n",
    "# Fit a higher-degree polynomial (e.g., degree=6)\n",
    "poly_high = PolynomialFeatures(degree=6)\n",
    "X_train_poly_high = poly_high.fit_transform(X_age_train)\n",
    "X_test_poly_high = poly_high.transform(X_age_test)\n",
    "\n",
    "# Fit model\n",
    "poly_model_high = LinearRegression()\n",
    "poly_model_high.fit(X_train_poly_high, y1_train)\n",
    "y_pred_poly_high = poly_model_high.predict(X_test_poly_high)\n",
    "\n",
    "# Plot predictions vs actuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_age_test, y1_test, color='blue', label='Actual')\n",
    "plt.scatter(X_age_test, y_pred_poly_high, color='orange', label='Predicted (Degree 6)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.title(\"Polynomial Regression (Degree 6): Age vs Fare\")\n",
    "plt.savefig\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Final Thoughts & Insights\n",
    "Your notebook should tell a data story. Use this section to demonstrate your thinking and value as an analyst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Summarize Findings\n",
    "\n",
    "**What features were most useful?** The most useful features were pclass, age, and family size. Together, they gave the model more to work with and helped it understand different fare levels better. Using just one feature like age didn’t give strong results.\n",
    "\n",
    "**What regression model performed best?** The polynomial regression (degree 6) gave the best results overall — it captured patterns better than the basic linear model and handled combinations of features well. Ridge and ElasticNet were close but didn’t beat the polynomial model.\n",
    "\n",
    "\n",
    "**How did model complexity or regularization affect results?**\n",
    "- Higher-degree polynomial models (like degree 6) started to overfit — they followed the noise too much and looked less stable.\n",
    "\n",
    "- Regularization (like Ridge and ElasticNet) helped keep the models simpler, which is useful when working with lots of features or noisy data.\n",
    "\n",
    "- In the end, a balanced model (like polynomial degree 6) gave the best mix of accuracy and generalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Discuss Challenges\n",
    "\n",
    "**Was fare hard to predict?** Yes, fare was a bit tricky to predict. \n",
    "\n",
    "**Why?** There were a lot of factors that influenced it — like class, group size, maybe even where someone got on the ship — but we didn’t have all of that in the model. Some features like age didn’t help much, so the model struggled unless I combined stronger features as in Case 4\n",
    "\n",
    "**Did skew or outliers impact the models?** Yes, definitely. There were some really high fares that pulled the model off, especially when using mean-based metrics like RMSE. Those outliers made it harder for the model to fit the average cases well. Some regularization and polynomial models helped, but the extreme fare values still made predictions a bit messy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Optional Next Steps\n",
    "\n",
    "**Try different features besides the ones used (e.g., pclass, sex if you didn't use them this time)** I’d like to try adding sex, embarked, or even deck next time — they might give the model more insight into passenger types and how that relates to fare. We used pclass, age, and family size, but there’s still more info in the dataset to explore.\n",
    "\n",
    "**Try predicting age instead of fare** That could be interesting! Age might be a little more stable to predict than fare since it’s not affected by ticket prices or travel class. It would be a good way to flip the problem and see how different features relate to age.\n",
    "\n",
    "**Explore log transformation of fare to reduce skew** Yes — fare had a few really high outliers that skewed the results. Taking the log of the fare could smooth things out and make the model less sensitive to those extreme values. That’s definitely something I’d try next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
