{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Project (Titanic)\n",
    "Jason Ballard\n",
    "31 March 2025\n",
    "\n",
    "Import the external Python libraries used (e.g., pandas, numpy, matplotlib, seaborn, sklearn and more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports get moved to the top - import each only once\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "features = list(df.columns)\n",
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic.info()\n",
    "# print(titanic.head(10))\n",
    "# titanic.isnull().sum()\n",
    "# print(titanic.describe())\n",
    "# print(titanic.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes = ['age', 'fare', 'pclass']\n",
    "# scatter_matrix(titanic[attributes], figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(titanic['age'], titanic['fare'], c=titanic['sex'].apply(lambda x: 0 if x == 'male' else 1))\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Fare')\n",
    "# plt.title('Age vs Fare by Gender')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a histogram of age:\n",
    "\n",
    "# sns.histplot(titanic['age'], kde=True)\n",
    "# plt.title('Age Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a count plot for class and survival:\n",
    "\n",
    "# sns.countplot(x='class', hue='survived', data=titanic)\n",
    "# plt.title('Class Distribution by Survival')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.1:\n",
    "\n",
    "1. What patterns or anomalies do you notice? Young to middle age passengers, majority found in third class\n",
    "2. Do any features stand out as potential predictors? the deck location or fare price\n",
    "3. Are there any visible class imbalances? There are huge class imbalances. Majority of the passengers where younger families traveling to the USA -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handle Missing Values and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values in 'age' with the median age\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "# impute missing values in 'embark_town' with the mode (most common value)`\n",
    "# 'embark_town' has 2 missing values, so we can use the mode to fill them\n",
    "df['embark_town'].fillna(df['embark_town'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature: Family size\n",
    "# This is the coveresion of catagorical dat inot numerical data\n",
    "\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1 \n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1})\n",
    "df['embark_town'] = df['embark_town'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "df['alone'] = df['alone'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.3\n",
    "\n",
    "1. Why might family size be a useful feature for predicting survival? famil;y size is a good prediction of survivalbility for the female and younger children of the families\n",
    "2. Why convert categorical data to numeric?  the conversion allows computations to be run on the data. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Feature Selection and Justification\n",
    "\n",
    "- Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "- Use 'Survived' as the target\n",
    "\n",
    "First:\n",
    "- input features: alone\n",
    "- target: survived\n",
    "\n",
    "Second:\n",
    "- input features - embark_town\n",
    "- target: survived\n",
    "\n",
    "Third:\n",
    "- input features -  age and family_size (embark_town)\n",
    "- target: survived\n",
    "- Justify your selection with reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Choose features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a new feature 'family_size' (sum of siblings/spouses and parents/children aboard)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mfamily_size\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33msibsp\u001b[39m\u001b[33m'\u001b[39m] + df[\u001b[33m'\u001b[39m\u001b[33mparch\u001b[39m\u001b[33m'\u001b[39m] + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# +1 to include the passenger themselves\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Select relevant features for classification\u001b[39;00m\n\u001b[32m      5\u001b[39m features = [\u001b[33m'\u001b[39m\u001b[33malone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mage\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33membark\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msex\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfamily_size\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a new feature 'family_size' (sum of siblings/spouses and parents/children aboard)\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1  # +1 to include the passenger themselves\n",
    "\n",
    "# Select relevant features for classification\n",
    "features = ['alone', 'age', 'embark', 'sex', 'family_size']\n",
    "target = 'survived'\n",
    "\n",
    "# Extract relevant columns\n",
    "titanic_classification = df[features + [target]]\n",
    "\n",
    "# Encode categorical variable 'sex' (convert 'male'/'female' to 0/1)\n",
    "titanic_classification['sex'] = titanic_classification['sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Drop rows with missing values\n",
    "titanic_classification = titanic_classification.dropna()\n",
    "\n",
    "# Display the processed dataset\n",
    "print(titanic_classification.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define X (features) and y (target)\n",
    "- Assign input features to X a pandas DataFrame with 1 or more input features\n",
    "- Assign target variable to y (as applicable) - a pandas Series with a single target feature\n",
    "- Again - use comments to run a single case at a time\n",
    "\n",
    "- The follow starts with only the statements needed for case 1. \n",
    "- Double brackets [[ ]]  makes a 2D DataFrame\n",
    "- Single brackets [ ]  make a 1D Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1 Assign input features to X = (alone)\n",
    "X = df['alone']\n",
    "# Assign target variable to y (as applicable)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 Assign input features to X = embarked\n",
    "X = df['embark_town']\n",
    "# Assign target variable to y (as applicable)   \n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['family_size'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#  Case 3 Assign input features to X = \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mage\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membarked\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfamily_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Assign target variable to y (as applicable)\u001b[39;00m\n\u001b[32m      4\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33msurvived\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\balla\\Projects\\applied-ml-jballard\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\balla\\Projects\\applied-ml-jballard\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\balla\\Projects\\applied-ml-jballard\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['family_size'] not in index\""
     ]
    }
   ],
   "source": [
    "#  Case 3 Assign input features to X = \n",
    "X = df[['age', 'embark_town', 'family_size']]\n",
    "# Assign target variable to y (as applicable)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "\n",
    "1. Why are these features selected? the features selected provide the most tell of survivability\n",
    "2. Are there any features that are likely to be highly predictive of survival? Yes age and class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Basic Train/Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print('Train size:', len(X_train))\n",
    "print('Test size:', len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Stratified Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    train_set = X.iloc[train_indices]\n",
    "    test_set = X.iloc[test_indices]\n",
    "\n",
    "print('Train size:', len(train_set))\n",
    "print('Test size:', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Compare Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "print(\"Original Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Train Set Class Distribution:\\n\", train_set['pclass'].value_counts(normalize=True))\n",
    "print(\"Test Set Class Distribution:\\n\", test_set['pclass'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "\n",
    "1. Why might stratification improve model performance? this ensures that the data is equallly representivate across the whole data set. \n",
    "2. How close are the training and test distributions to the original dataset?\n",
    "3. Which split method produced better class balance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
