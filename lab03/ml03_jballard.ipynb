{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Project (Titanic)\n",
    "Jason Ballard\n",
    "31 March 2025\n",
    "\n",
    "Import the external Python libraries used (e.g., pandas, numpy, matplotlib, seaborn, sklearn and more)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports get moved to the top - import each only once\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "features = list(df.columns)\n",
    "print(features)\n",
    "print(len(features))\n",
    "# Understand the data\n",
    "print(df.info())       # See column types and missing values\n",
    "print(df.head(3))      # Peek at the structure\n",
    "print(df.describe())   # Summary stats for numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Handle Missing Values, Clean Data, and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Fill missing values and create new features\n",
    "df['family_size'] = df['sibsp'] + df['parch'] + 1\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "df['embark_town'] = df['embark_town'].fillna(df['embark_town'].mode()[0])\n",
    "df['sex'] = df['sex'].map({'male': 0, 'female': 1, 'unknown': -1})\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['embark_town_encoded'] = label_encoder.fit_transform(df['embark_town'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Reflection 2.3\n",
    "\n",
    "1. Why might family size be a useful feature for predicting survival? famil;y size is a good prediction of survivalbility for the female and younger children of the families\n",
    "2. Why convert categorical data to numeric?  the conversion allows computations to be run on the data. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Feature Selection and Justification\n",
    "\n",
    "- Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "- Use 'Survived' as the target\n",
    "\n",
    "First:\n",
    "- input features: alone\n",
    "- target: survived\n",
    "\n",
    "Second:\n",
    "- input features - embark_town\n",
    "- target: survived\n",
    "\n",
    "Third:\n",
    "- input features -  age and family_size (embark_town)\n",
    "- target: survived\n",
    "- Justify your selection with reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Choose features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the available features and target\n",
    "features = ['alone', 'age', 'family_size', 'embark_town_encoded', 'sex']\n",
    "target = 'survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define X (features) and y (target)\n",
    "- Assign input features to X a pandas DataFrame with 1 or more input features\n",
    "- Assign target variable to y (as applicable) - a pandas Series with a single target feature\n",
    "- Again - use comments to run a single case at a time\n",
    "\n",
    "- The follow starts with only the statements needed for case 1. \n",
    "- Double brackets [[ ]]  makes a 2D DataFrame\n",
    "- Single brackets [ ]  make a 1D Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_case(case_number, df):\n",
    "    if case_number == 1:\n",
    "        feature_list = ['alone']\n",
    "    elif case_number == 2:\n",
    "        feature_list = ['embark_town_encoded']\n",
    "    elif case_number == 3:\n",
    "        feature_list = ['age', 'family_size', 'embark_town_encoded']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid case number.\")\n",
    "\n",
    "    X = df[feature_list].dropna()\n",
    "    y = df.loc[X.index, 'survived']\n",
    "    return X, y, feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Select and run a Specific Case (loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in [1, 2, 3]:\n",
    "    X, y, features = select_case(case, df)\n",
    "    print(f\"Running Case {case} with features: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Eval Features \n",
    "Plot correlations, value counts, or feature distributions\n",
    "\n",
    "Help to justify why the features were selected (especially for reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of numerical features with 'survived'\n",
    "print(df[features + ['survived']].corr()['survived'].sort_values(ascending=False))\n",
    "\n",
    "# Visualize feature distribution\n",
    "sns.pairplot(df[features + ['survived']], hue='survived')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "\n",
    "1. Why are these features selected? **the features selected provide the most tell of survivability**\n",
    "2. Are there any features that are likely to be highly predictive of survival? **Yes age and class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Train a Classification Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Basic Train/Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stratified_split(X, y, test_size=0.2, random_state=42):\n",
    "#     splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "#     for train_idx, test_idx in splitter.split(X, y):\n",
    "#         return X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = stratified_split(X, y)\n",
    "#     print(f\"Train set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
    "#     return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=123)\n",
    "\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Stratified Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Compare Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "print(\"Train Set Class Distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Test Set Class Distribution:\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Eval the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_tree(tree_model, feature_names=X.columns, class_names=['Died', 'Survived'], filled=True)\n",
    "plt.title('Decision Tree Visualization')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "\n",
    "1. Why might stratification improve model performance? **This ensures that the data is equallly representivate across the whole data set.**\n",
    "2. How close are the training and test distributions to the original dataset? **identical**\n",
    "3. Which split method produced better class balance? **I am not sure because th enumbers are so close**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Compare Alternative Models (SVC, NN) \n",
    "\n",
    "In a Support Vector Machine, the kernel function defines how the algorithm transforms data to find a hyperplane that separates the classes. If the data is not linearly separable, changing the kernel can help the model find a better decision boundary.\n",
    "\n",
    "SVC Kernel: Common Types\n",
    "\n",
    "RBF (Radial Basis Function) – Most commonly used; handles non-linear data well (default)\n",
    "Linear – Best for linearly separable data (straight line separation)\n",
    "Polynomial – Useful when the data follows a curved pattern\n",
    "Sigmoid – Similar to a neural network activation function; less common\n",
    "Commenting the options in and out in the code can be helpful. The analyst decides which to use based on their understanding of the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernels = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "# for kernel in kernels:\n",
    "#     model = SVC(kernel=kernel)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     acc = accuracy_score(y_test, y_pred)\n",
    "#     print(f\"SVC Kernel: {kernel} | Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Train and Evaluate Model (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    svc = SVC(kernel=kernel)\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nSVC Kernel: {kernel}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1A  Dynamic plot- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature = X.columns[0]  # Dynamically pick the first feature\n",
    "\n",
    "survived_vals = X_test.loc[y_test == 1, plot_feature]\n",
    "not_survived_vals = X_test.loc[y_test == 0, plot_feature]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(survived_vals, y_test[y_test == 1], c='yellow', marker='s', label='Survived')\n",
    "plt.scatter(not_survived_vals, y_test[y_test == 0], c='cyan', marker='^', label='Not Survived')\n",
    "\n",
    "if hasattr(svc, 'support_vectors_'):\n",
    "    support_x = svc.support_vectors_[:, 0]\n",
    "    support_y = svc.support_vectors_[:, 1] if svc.support_vectors_.shape[1] > 1 else None\n",
    "    if support_y is not None:\n",
    "        plt.scatter(support_x, support_y, c='black', marker='+', label='Support Vectors')\n",
    "    else:\n",
    "        plt.scatter(support_x, [0]*len(support_x), c='black', marker='+', label='Support Vectors')\n",
    "\n",
    "plt.xlabel(plot_feature)\n",
    "plt.ylabel('Survived')\n",
    "plt.title('Support Vectors (SVC)')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Train and Evaluate Model (NN MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = MLPClassifier(hidden_layer_sizes=(50, 25, 10), solver='lbfgs')\n",
    "nn_model.fit(X_train, y_train) \n",
    "\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "\n",
    "print(\"Results for Neural Network on test data:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "sns.heatmap(cm_nn, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison Summary Table\n",
    "results = {\n",
    "    \"Model\": [\"Decision Tree\", \"SVC (rbf)\", \"SVC (linear)\", \"Neural Net\"],\n",
    "    \"Accuracy\": [dt_acc, svc_rbf_acc, svc_linear_acc, nn_acc]  # replace with your actual values\n",
    "}\n",
    "pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection 5:\n",
    "How well did each model perform?\n",
    "\n",
    "Are there any surprising results?\n",
    "\n",
    "Why might one model outperform the others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Final Thoughts & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Summarize Findings\n",
    "What indicators are strong predictors of gender?\n",
    "\n",
    "Decision Tree performed well but overfit slightly on training data.\n",
    "\n",
    "Neural Network showed moderate improvement but introduced complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Discuss Challenges Faced\n",
    "Small sample size could limit generalizability.\n",
    "\n",
    "Missing values (if any) could bias the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Next Steps\n",
    "Test more features (e.g., BMI class). \n",
    "\n",
    "Try hyperparameter tuning for better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
